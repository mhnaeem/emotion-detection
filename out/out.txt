"/Users/hammad/Documents/School/Winter 2021/COMP_4301/CS4301/venv/bin/python" "/Users/hammad/Documents/School/Winter 2021/COMP_4301/CS4301/Term_Project/Code/new_model.py"
Reading data...
Data Read Complete!
Creating a Sequential model
2021-03-11 21:00:19.862733: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-03-11 21:00:19.862935: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
conv2d (Conv2D)              (None, 46, 46, 32)        320
_________________________________________________________________
activation (Activation)      (None, 46, 46, 32)        0
_________________________________________________________________
max_pooling2d (MaxPooling2D) (None, 23, 23, 32)        0
_________________________________________________________________
batch_normalization (BatchNo (None, 23, 23, 32)        128
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 21, 21, 64)        18496
_________________________________________________________________
activation_1 (Activation)    (None, 21, 21, 64)        0
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 10, 10, 64)        0
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 8, 8, 64)          36928
_________________________________________________________________
dropout (Dropout)            (None, 8, 8, 64)          0
_________________________________________________________________
activation_2 (Activation)    (None, 8, 8, 64)          0
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 4, 4, 64)          0
_________________________________________________________________
batch_normalization_1 (Batch (None, 4, 4, 64)          256
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 2, 2, 128)         73856
_________________________________________________________________
activation_3 (Activation)    (None, 2, 2, 128)         0
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 1, 1, 128)         0
_________________________________________________________________
flatten (Flatten)            (None, 128)               0
_________________________________________________________________
dense (Dense)                (None, 128)               16512
_________________________________________________________________
activation_4 (Activation)    (None, 128)               0
_________________________________________________________________
flatten_1 (Flatten)          (None, 128)               0
_________________________________________________________________
dense_1 (Dense)              (None, 64)                8256
_________________________________________________________________
activation_5 (Activation)    (None, 64)                0
_________________________________________________________________
flatten_2 (Flatten)          (None, 64)                0
_________________________________________________________________
dense_2 (Dense)              (None, 32)                2080
_________________________________________________________________
activation_6 (Activation)    (None, 32)                0
_________________________________________________________________
dense_3 (Dense)              (None, 2)                 66
_________________________________________________________________
activation_7 (Activation)    (None, 2)                 0
=================================================================
Total params: 156,898
Trainable params: 156,706
Non-trainable params: 192
_________________________________________________________________
None
Model Creation Complete!
2021-03-11 21:00:20.025096: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
Epoch 1/50
381/381 [==============================] - 17s 43ms/step - loss: 0.3341 - accuracy: 0.5826 - val_loss: 0.7103 - val_accuracy: 0.5841

Epoch 00001: val_loss improved from inf to 0.71032, saving model to emotion_model.h5
Epoch 2/50
381/381 [==============================] - 17s 44ms/step - loss: 0.3242 - accuracy: 0.5847 - val_loss: 0.6710 - val_accuracy: 0.5841

Epoch 00002: val_loss improved from 0.71032 to 0.67097, saving model to emotion_model.h5
Epoch 3/50
381/381 [==============================] - 19s 49ms/step - loss: 0.3182 - accuracy: 0.5947 - val_loss: 0.6418 - val_accuracy: 0.5860

Epoch 00003: val_loss improved from 0.67097 to 0.64184, saving model to emotion_model.h5
Epoch 4/50
381/381 [==============================] - 19s 51ms/step - loss: 0.3136 - accuracy: 0.5989 - val_loss: 0.6734 - val_accuracy: 0.5841

Epoch 00004: val_loss did not improve from 0.64184
Epoch 5/50
381/381 [==============================] - 22s 57ms/step - loss: 0.3050 - accuracy: 0.6048 - val_loss: 0.5978 - val_accuracy: 0.5854

Epoch 00005: val_loss improved from 0.64184 to 0.59777, saving model to emotion_model.h5
Epoch 6/50
381/381 [==============================] - 22s 58ms/step - loss: 0.3020 - accuracy: 0.6093 - val_loss: 0.5894 - val_accuracy: 0.5880

Epoch 00006: val_loss improved from 0.59777 to 0.58939, saving model to emotion_model.h5
Epoch 7/50
381/381 [==============================] - 21s 55ms/step - loss: 0.2935 - accuracy: 0.6194 - val_loss: 0.5186 - val_accuracy: 0.6917

Epoch 00007: val_loss improved from 0.58939 to 0.51864, saving model to emotion_model.h5
Epoch 8/50
381/381 [==============================] - 20s 52ms/step - loss: 0.2900 - accuracy: 0.6391 - val_loss: 0.5155 - val_accuracy: 0.7681

Epoch 00008: val_loss improved from 0.51864 to 0.51553, saving model to emotion_model.h5
Epoch 9/50
381/381 [==============================] - 19s 51ms/step - loss: 0.2841 - accuracy: 0.6584 - val_loss: 0.4512 - val_accuracy: 0.8040

Epoch 00009: val_loss improved from 0.51553 to 0.45119, saving model to emotion_model.h5
Epoch 10/50
381/381 [==============================] - 19s 51ms/step - loss: 0.2767 - accuracy: 0.6714 - val_loss: 0.5127 - val_accuracy: 0.7561

Epoch 00010: val_loss did not improve from 0.45119
Epoch 11/50
381/381 [==============================] - 20s 51ms/step - loss: 0.2664 - accuracy: 0.6871 - val_loss: 0.4654 - val_accuracy: 0.7641

Epoch 00011: val_loss did not improve from 0.45119
Epoch 12/50
381/381 [==============================] - 19s 51ms/step - loss: 0.2600 - accuracy: 0.7036 - val_loss: 0.3961 - val_accuracy: 0.8226

Epoch 00012: val_loss improved from 0.45119 to 0.39606, saving model to emotion_model.h5
Epoch 13/50
381/381 [==============================] - 21s 55ms/step - loss: 0.2542 - accuracy: 0.7177 - val_loss: 0.4998 - val_accuracy: 0.8053

Epoch 00013: val_loss did not improve from 0.39606
Epoch 14/50
381/381 [==============================] - 24s 62ms/step - loss: 0.2541 - accuracy: 0.7048 - val_loss: 0.3845 - val_accuracy: 0.8319

Epoch 00014: val_loss improved from 0.39606 to 0.38447, saving model to emotion_model.h5
Epoch 15/50
381/381 [==============================] - 24s 63ms/step - loss: 0.2544 - accuracy: 0.7115 - val_loss: 0.4042 - val_accuracy: 0.8053

Epoch 00015: val_loss did not improve from 0.38447
Epoch 16/50
381/381 [==============================] - 23s 60ms/step - loss: 0.2398 - accuracy: 0.7366 - val_loss: 0.3289 - val_accuracy: 0.8551

Epoch 00016: val_loss improved from 0.38447 to 0.32889, saving model to emotion_model.h5
Epoch 17/50
381/381 [==============================] - 24s 63ms/step - loss: 0.2365 - accuracy: 0.7468 - val_loss: 0.3205 - val_accuracy: 0.8744

Epoch 00017: val_loss improved from 0.32889 to 0.32054, saving model to emotion_model.h5
Epoch 18/50
381/381 [==============================] - 25s 65ms/step - loss: 0.2333 - accuracy: 0.7451 - val_loss: 0.3466 - val_accuracy: 0.8498

Epoch 00018: val_loss did not improve from 0.32054
Epoch 19/50
381/381 [==============================] - 24s 62ms/step - loss: 0.2348 - accuracy: 0.7458 - val_loss: 0.3395 - val_accuracy: 0.8505

Epoch 00019: val_loss did not improve from 0.32054
Epoch 20/50
381/381 [==============================] - 22s 58ms/step - loss: 0.2357 - accuracy: 0.7534 - val_loss: 0.3721 - val_accuracy: 0.8179

Epoch 00020: val_loss did not improve from 0.32054

Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.
Epoch 21/50
381/381 [==============================] - 22s 58ms/step - loss: 0.2246 - accuracy: 0.7620 - val_loss: 0.2926 - val_accuracy: 0.8811

Epoch 00021: val_loss improved from 0.32054 to 0.29258, saving model to emotion_model.h5
Epoch 22/50
381/381 [==============================] - 23s 61ms/step - loss: 0.2178 - accuracy: 0.7674 - val_loss: 0.2718 - val_accuracy: 0.8864

Epoch 00022: val_loss improved from 0.29258 to 0.27176, saving model to emotion_model.h5
Epoch 23/50
381/381 [==============================] - 25s 65ms/step - loss: 0.2180 - accuracy: 0.7714 - val_loss: 0.2696 - val_accuracy: 0.8870

Epoch 00023: val_loss improved from 0.27176 to 0.26957, saving model to emotion_model.h5
Epoch 24/50
381/381 [==============================] - 26s 69ms/step - loss: 0.2168 - accuracy: 0.7756 - val_loss: 0.2813 - val_accuracy: 0.8870

Epoch 00024: val_loss did not improve from 0.26957
Epoch 25/50
381/381 [==============================] - 26s 67ms/step - loss: 0.2164 - accuracy: 0.7775 - val_loss: 0.2771 - val_accuracy: 0.8850

Epoch 00025: val_loss did not improve from 0.26957
Epoch 26/50
381/381 [==============================] - 25s 65ms/step - loss: 0.2122 - accuracy: 0.7758 - val_loss: 0.2663 - val_accuracy: 0.9023

Epoch 00026: val_loss improved from 0.26957 to 0.26626, saving model to emotion_model.h5
Epoch 27/50
381/381 [==============================] - 25s 65ms/step - loss: 0.2114 - accuracy: 0.7836 - val_loss: 0.2601 - val_accuracy: 0.9030

Epoch 00027: val_loss improved from 0.26626 to 0.26015, saving model to emotion_model.h5
Epoch 28/50
381/381 [==============================] - 26s 67ms/step - loss: 0.2136 - accuracy: 0.7777 - val_loss: 0.2522 - val_accuracy: 0.8957

Epoch 00028: val_loss improved from 0.26015 to 0.25221, saving model to emotion_model.h5
Epoch 29/50
381/381 [==============================] - 24s 64ms/step - loss: 0.2073 - accuracy: 0.7831 - val_loss: 0.2593 - val_accuracy: 0.8924

Epoch 00029: val_loss did not improve from 0.25221
Epoch 30/50
381/381 [==============================] - 25s 65ms/step - loss: 0.2100 - accuracy: 0.7829 - val_loss: 0.2677 - val_accuracy: 0.8950

Epoch 00030: val_loss did not improve from 0.25221
Epoch 31/50
381/381 [==============================] - 25s 65ms/step - loss: 0.2061 - accuracy: 0.7800 - val_loss: 0.2541 - val_accuracy: 0.8957

Epoch 00031: val_loss did not improve from 0.25221

Epoch 00031: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.
Epoch 32/50
381/381 [==============================] - 26s 69ms/step - loss: 0.2069 - accuracy: 0.7835 - val_loss: 0.2485 - val_accuracy: 0.9017

Epoch 00032: val_loss improved from 0.25221 to 0.24852, saving model to emotion_model.h5
Epoch 33/50
381/381 [==============================] - 25s 67ms/step - loss: 0.2097 - accuracy: 0.7908 - val_loss: 0.2496 - val_accuracy: 0.8970

Epoch 00033: val_loss did not improve from 0.24852
Epoch 34/50
381/381 [==============================] - 27s 72ms/step - loss: 0.2029 - accuracy: 0.7910 - val_loss: 0.2490 - val_accuracy: 0.8997

Epoch 00034: val_loss did not improve from 0.24852
Epoch 35/50
381/381 [==============================] - 28s 75ms/step - loss: 0.2026 - accuracy: 0.7937 - val_loss: 0.2489 - val_accuracy: 0.8997

Epoch 00035: val_loss did not improve from 0.24852

Epoch 00035: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.
Epoch 36/50
381/381 [==============================] - 26s 67ms/step - loss: 0.2007 - accuracy: 0.7947 - val_loss: 0.2471 - val_accuracy: 0.9010

Epoch 00036: val_loss improved from 0.24852 to 0.24711, saving model to emotion_model.h5
Epoch 37/50
381/381 [==============================] - 25s 67ms/step - loss: 0.2079 - accuracy: 0.7853 - val_loss: 0.2474 - val_accuracy: 0.9017

Epoch 00037: val_loss did not improve from 0.24711
Epoch 38/50
381/381 [==============================] - 27s 71ms/step - loss: 0.2026 - accuracy: 0.7929 - val_loss: 0.2467 - val_accuracy: 0.9010

Epoch 00038: val_loss improved from 0.24711 to 0.24671, saving model to emotion_model.h5
Epoch 39/50
381/381 [==============================] - 27s 72ms/step - loss: 0.2073 - accuracy: 0.7863 - val_loss: 0.2477 - val_accuracy: 0.8997

Epoch 00039: val_loss did not improve from 0.24671
Epoch 40/50
381/381 [==============================] - 29s 76ms/step - loss: 0.2014 - accuracy: 0.7925 - val_loss: 0.2460 - val_accuracy: 0.9017

Epoch 00040: val_loss improved from 0.24671 to 0.24605, saving model to emotion_model.h5
Epoch 41/50
381/381 [==============================] - 30s 78ms/step - loss: 0.2019 - accuracy: 0.7943 - val_loss: 0.2464 - val_accuracy: 0.9010

Epoch 00041: val_loss did not improve from 0.24605
Epoch 42/50
381/381 [==============================] - 30s 79ms/step - loss: 0.2044 - accuracy: 0.7879 - val_loss: 0.2456 - val_accuracy: 0.9017

Epoch 00042: val_loss improved from 0.24605 to 0.24557, saving model to emotion_model.h5
Epoch 43/50
381/381 [==============================] - 30s 80ms/step - loss: 0.2009 - accuracy: 0.7905 - val_loss: 0.2458 - val_accuracy: 0.9017

Epoch 00043: val_loss did not improve from 0.24557
Epoch 44/50
381/381 [==============================] - 30s 79ms/step - loss: 0.1944 - accuracy: 0.7996 - val_loss: 0.2453 - val_accuracy: 0.9017

Epoch 00044: val_loss improved from 0.24557 to 0.24529, saving model to emotion_model.h5
Epoch 45/50
381/381 [==============================] - 30s 79ms/step - loss: 0.1975 - accuracy: 0.7967 - val_loss: 0.2458 - val_accuracy: 0.9010

Epoch 00045: val_loss did not improve from 0.24529
Epoch 46/50
381/381 [==============================] - 28s 74ms/step - loss: 0.2036 - accuracy: 0.7925 - val_loss: 0.2463 - val_accuracy: 0.9017

Epoch 00046: val_loss did not improve from 0.24529
Epoch 47/50
381/381 [==============================] - 27s 71ms/step - loss: 0.1991 - accuracy: 0.8039 - val_loss: 0.2458 - val_accuracy: 0.9003

Epoch 00047: val_loss did not improve from 0.24529

Epoch 00047: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.
Epoch 48/50
381/381 [==============================] - 26s 67ms/step - loss: 0.1980 - accuracy: 0.7981 - val_loss: 0.2460 - val_accuracy: 0.9010

Epoch 00048: val_loss did not improve from 0.24529
Epoch 49/50
381/381 [==============================] - 29s 76ms/step - loss: 0.2022 - accuracy: 0.7964 - val_loss: 0.2471 - val_accuracy: 0.9017
Restoring model weights from the end of the best epoch.

Epoch 00049: val_loss did not improve from 0.24529
Epoch 00049: early stopping
47/47 [==============================] - 1s 18ms/step - loss: 0.3031 - accuracy: 0.8742
Validation Accuracy: 0.874167799949646,
Validation Loss: 0.303075909614563

Process finished with exit code 0
